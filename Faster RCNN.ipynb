{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport csv\n\n# Path to the COCO annotated JSON file\njson_file_path = '/kaggle/input/taco-single-class/data/data/custom_val.json'\n\n# Path to the CSV file you want to create\ncsv_file_path = 'output.csv'\n\ndef convert_coco_to_csv(json_file_path, csv_file_path):\n    with open(json_file_path, 'r') as json_file:\n        coco_data = json.load(json_file)\n\n    images = coco_data['images']\n    annotations = coco_data['annotations']\n\n    # Create a dictionary to store image information by image ID\n    image_info = {}\n    for image in images:\n        image_info[image['id']] = {\n            'filename': image['file_name'],\n            'width': image['width'],\n            'height': image['height']\n        }\n\n    # Create a list to store annotation information\n    annotation_list = []\n    for annotation in annotations:\n        image_id = annotation['image_id']\n        image_info_entry = image_info.get(image_id)\n        if image_info_entry:\n            annotation_entry = {\n                'image': image_info_entry['filename'],\n                'xmin': annotation['bbox'][0],\n                'ymin': annotation['bbox'][1],\n                'xmax': annotation['bbox'][0] + annotation['bbox'][2],\n                'ymax': annotation['bbox'][1] + annotation['bbox'][3]\n            }\n            annotation_list.append(annotation_entry)\n\n    # Write the data to a CSV file\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        fieldnames = ['image', 'xmin', 'ymin', 'xmax', 'ymax']\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        writer.writeheader()\n        writer.writerows(annotation_list)\n\nconvert_coco_to_csv(json_file_path, csv_file_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-16T16:02:05.904080Z","iopub.execute_input":"2023-10-16T16:02:05.905055Z","iopub.status.idle":"2023-10-16T16:02:05.969685Z","shell.execute_reply.started":"2023-10-16T16:02:05.905017Z","shell.execute_reply":"2023-10-16T16:02:05.968611Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2023-10-16T16:02:06.123795Z","iopub.execute_input":"2023-10-16T16:02:06.126353Z","iopub.status.idle":"2023-10-16T16:02:18.261356Z","shell.execute_reply.started":"2023-10-16T16:02:06.126298Z","shell.execute_reply":"2023-10-16T16:02:18.260178Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.23.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.5.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\nfrom torchvision.transforms import functional as F\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom torchvision.models.detection.backbone_utils import resnet_fpn_backbone\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n# Load the Fast R-CNN model\nbackbone = resnet_fpn_backbone('resnet101', pretrained=True)\nmodel = FasterRCNN(backbone,num_classes=2)\nmodel.load_state_dict(torch.load('/kaggle/input/taco-model/best_model.pth'))\nmodel.eval()\n\n# Directory containing images\nimage_dir = '/kaggle/input/taco-single-class/data/data/'\n\n# JSON file containing COCO format annotations\ncoco_json_file = '/kaggle/input/taco-single-class/data/data/custom_val.json'\n\n# Load COCO annotations from the JSON file\ncoco_gt = COCO(coco_json_file)\n\n# Create a list to store the results\nresults = []\n\n# Loop through each annotation in the COCO dataset\nfor annotation in coco_gt.dataset['annotations']:\n    image_id = annotation['image_id']\n    image_info = coco_gt.loadImgs(image_id)[0]\n    image_filename = os.path.join(image_dir, image_info['file_name'])\n    class_id = annotation['category_id']\n    ground_truth_box = annotation['bbox']\n\n    # Perform object detection on the current image\n    image = Image.open(image_filename)\n    image_tensor = F.to_tensor(image)\n    with torch.no_grad():\n        predictions = model([image_tensor])\n        \n    # Retrieve the predicted bounding boxes, labels, and scores\n    predicted_boxes = predictions[0]['boxes']\n    predicted_labels = predictions[0]['labels']\n    predicted_scores = predictions[0]['scores']\n\n\n    # Store the results in COCO format\n    for bbox in predicted_boxes:\n        results.append({\n            'image_id': image_id,\n            'category_id': class_id,\n            'bbox': [bbox[0].item(), bbox[1].item(), bbox[2].item() - bbox[0].item(), bbox[3].item() - bbox[1].item()],\n            'score': 1.0  # You can set a fixed score since you're not calculating confidence scores\n        })\n\n\n# Initialize COCO evaluation\ncoco_dt = coco_gt.loadRes(results)\ncoco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n\n# Run the evaluation\ncoco_eval.evaluate()\ncoco_eval.accumulate()\ncoco_eval.summarize()\n\n# Print the metrics in the specified format\nprint(\"IoU metric: bbox\")\nprint(f\"Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = {coco_eval.stats[0]:.3f}\")\nprint(f\"Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = {coco_eval.stats[1]:.3f}\")\nprint(f\"Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = {coco_eval.stats[2]:.3f}\")\nprint(f\"Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = {coco_eval.stats[3]:.3f}\")\nprint(f\"Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = {coco_eval.stats[4]:.3f}\")\nprint(f\"Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = {coco_eval.stats[5]:.3f}\")\nprint(f\"Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = {coco_eval.stats[6]:.3f}\")\nprint(f\"Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = {coco_eval.stats[7]:.3f}\")\nprint(f\"Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = {coco_eval.stats[8]:.3f}\")\nprint(f\"Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = {coco_eval.stats[9]:.3f}\")\nprint(f\"Average Recall     (AR) @[ IoU=0.50:0.95 | area= medium | maxDets=100 ] = {coco_eval.stats[10]:.3f}\")\nprint(f\"Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = {coco_eval.stats[11]:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-16T16:02:18.263891Z","iopub.execute_input":"2023-10-16T16:02:18.264240Z","iopub.status.idle":"2023-10-16T17:32:50.177055Z","shell.execute_reply.started":"2023-10-16T16:02:18.264205Z","shell.execute_reply":"2023-10-16T17:32:50.176018Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n100%|██████████| 171M/171M [00:00<00:00, 230MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.02s)\ncreating index...\nindex created!\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.90s).\nAccumulating evaluation results...\nDONE (t=0.18s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.039\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\nIoU metric: bbox\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\nAverage Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.039\nAverage Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= medium | maxDets=100 ] = 0.340\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}